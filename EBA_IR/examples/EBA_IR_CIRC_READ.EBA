// Copy for working on Oct 27, 2025
// modified for full use Dec 4, 2025
// args buffer contains:
// 0: name of own buffer code is resident in
// 1: name of circular buffer
// 2: name of destination buffer
// 3: buffer containing number of bytes to read

// V0 is always the arg buffer
LITERAL READ V13, V0, @08 // V13 is the circular buffer
LITERAL READ V14, V0, @16 // V14 is the destination buffer
LITERAL READ V15, V0, @24 // V15 is the size buffer
LITERAL READ V1, V13, @00
LITERAL READ V2, V13, @08
LITERAL READ V3, V13, @16
LITERAL READ V4, V13, @24
LITERAL READ V5, V13, @32
// V1 <- data_buf
// V2 <- size_buf
// V3 <- head_buf
// V4 <- tail_buf
// V5 <- full_buf

// working buffers
BUFREQ ALLOC_LITERAL V6, @8
BUFREQ ALLOC_LITERAL V7, @8
BUFREQ ALLOC_LITERAL V8, @8

// V6 will be the occupied space buffer
INVOKE MUL_U64 V6, V5, V2 // occ_space = full*size
INVOKE ADD_U64 V6, V6, V4 // occ_space += tail
INVOKE SUB_U64 V6, V6, V3 // occ_space -= head
CMP GEQ        V4, V3, SKIP_WRAPAROUND_ADD
// if tail_buf < head_buf, add size_buff
INVOKE ADD_U64 V6, V6, V2

SKIP_WRAPAROUND_ADD:
CMP GT         V15, V6, END
// if the amount of bytes to read is more than
// the occupied space in the buffer, end.
LITERAL LOAD V8, @8
TRANSFER FLAT  V7, V15, V8
// V7 is working read size, starting with V15 (bytes) bytes
INVOKE ADD_U64 V8, V15, V3
CMP LEQ        V8, V2, SKIP_WR_WRAPAROUND
// if read size + head > size, then we'll wrap around
INVOKE SUB_U64 V7, V2, V3
SKIP_WR_WRAPAROUND:
LITERAL LOAD V8, @0
// first read:
TRANSFER VARIABLE_SRCOFFSET V14, V8, V1, V7, V3
// transfer to V14 (dest buf)
// to the start of the buffer
// from V1 (data buf of the circular buffer)
// from offset V3 (head)
// of V7 bytes (working read size)
INVOKE ADD_U64 V3, V3, V7
INVOKE MOD_U64 V3, V3, V2
// head = (head + working_read_size) % size

INVOKE SUB_U64 V7, V14, V7
// working read size now holds the rest of what
// needs read

// should do a sanity check here: if V7 is
// zero, then we are done. Otherwise, another read
// is necessary
LITERAL LOAD V8, @0
CMP EQ         V7, V8, END

LITERAL LOAD V6, @0
// safe because we are done with V6 now: use it for a zero.
INVOKE SUB_U64 V8, V14, V7
// V8 contains what was read the first time
// we know if we are here at this point, it is
// because we looped around. We could add a sanity
// check if desired.
// second read
TRANSFER OFFSET V14, V8, V1, V6, V7
// transfer to V14 (dest buf)
// to offset V8 (size of first read)
// from V1 (data buf of the circular buffer)
// from the start of the buffer
// of V7 bytes (working read size)
INVOKE ADD_U64 V3, V3, V7
INVOKE MOD_U64 V3, V3, V2
// head = (head + working_read_size) % size

END:
LITERAL LOAD V8, @0
CMP EQ         V14, V8, NOWRITE // was anything read?
// if something was read, the buffer is certainly
// not full
LITERAL LOAD V5, @0

BUFREQ RELEASE V6
BUFREQ RELEASE V7
BUFREQ RELEASE V8

NOWRITE:
